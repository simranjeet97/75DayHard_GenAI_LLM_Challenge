{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-08T10:46:16.402794Z","iopub.status.idle":"2024-03-08T10:46:16.403695Z","shell.execute_reply.started":"2024-03-08T10:46:16.403395Z","shell.execute_reply":"2024-03-08T10:46:16.403417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FREEBIRDS CREW - GenAI 75 HARD : Day - 40 ","metadata":{}},{"cell_type":"markdown","source":"## Wikipedia Data Trained GPT-2 LLM\n\n![](https://img.freepik.com/premium-photo/robotic-detective-interrogating-suspect_783299-2053.jpg)","metadata":{}},{"cell_type":"code","source":"!pip install Wikipedia-API","metadata":{"execution":{"iopub.status.busy":"2024-03-08T17:12:49.501506Z","iopub.execute_input":"2024-03-08T17:12:49.501986Z","iopub.status.idle":"2024-03-08T17:13:03.644436Z","shell.execute_reply.started":"2024-03-08T17:12:49.501952Z","shell.execute_reply":"2024-03-08T17:13:03.643341Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting Wikipedia-API\n  Downloading Wikipedia_API-0.6.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from Wikipedia-API) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->Wikipedia-API) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->Wikipedia-API) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->Wikipedia-API) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->Wikipedia-API) (2024.2.2)\nDownloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\nInstalling collected packages: Wikipedia-API\nSuccessfully installed Wikipedia-API-0.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!!pip install -U transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wikipediaapi\n\nwiki_wiki = wikipediaapi.Wikipedia('FreeBirds Crew (freebirdscrew@gmail.com)','en')\n\ndef get_wikipedia_page(title):\n    page_py = wiki_wiki.page(title)\n    if not page_py.exists():\n        return None\n    return page_py.text\n\n# Example: Fetching the content of a Wikipedia page\npage_title = \"Python (programming language)\"\nwikipedia_data = get_wikipedia_page(page_title)\n\n# Save the data to a file\nwith open(\"wikipedia_data.txt\", \"w\", encoding=\"utf-8\") as file:\n    file.write(wikipedia_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T17:13:03.646905Z","iopub.execute_input":"2024-03-08T17:13:03.647307Z","iopub.status.idle":"2024-03-08T17:13:04.395035Z","shell.execute_reply.started":"2024-03-08T17:13:03.647267Z","shell.execute_reply":"2024-03-08T17:13:04.394266Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# with open(\"wikipedia_data.txt\", \"r\", encoding=\"utf-8\") as file:\n#     print(file.readlines())","metadata":{"execution":{"iopub.status.busy":"2024-03-08T17:13:55.666022Z","iopub.execute_input":"2024-03-08T17:13:55.666451Z","iopub.status.idle":"2024-03-08T17:13:55.670495Z","shell.execute_reply.started":"2024-03-08T17:13:55.666421Z","shell.execute_reply":"2024-03-08T17:13:55.669494Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers import TextDataset, DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments\n\nmodel_name = \"gpt2\"  # Choose the appropriate GPT-2 model\n\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:57:22.682476Z","iopub.execute_input":"2024-03-08T10:57:22.682900Z","iopub.status.idle":"2024-03-08T10:57:27.190042Z","shell.execute_reply.started":"2024-03-08T10:57:22.682868Z","shell.execute_reply":"2024-03-08T10:57:27.189246Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79fcd1287f244ddb981c425914b1c4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f52bc3c6f094455bb7b5246f0015e1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06dc0a8c448e4bb1a84ee5f735ae0b3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b7f338e48744f0dae1d26f6813bf639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94774d0b10b46e99f651a6258760cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2541339e43425b8cb0be6805ac4dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3a1d047e3a4bf69a28b04b9fd7a2cd"}},"metadata":{}}]},{"cell_type":"code","source":"# Prepare data for fine-tuning\ntrain_data = TextDataset(\n    tokenizer=tokenizer,\n    file_path=\"wikipedia_data.txt\",\n    block_size=128\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:57:33.731535Z","iopub.execute_input":"2024-03-08T10:57:33.732267Z","iopub.status.idle":"2024-03-08T10:57:34.011528Z","shell.execute_reply.started":"2024-03-08T10:57:33.732236Z","shell.execute_reply":"2024-03-08T10:57:34.010702Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False  # Set to True for masked language modeling tasks\n)\ndata_collator","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:57:52.547121Z","iopub.execute_input":"2024-03-08T10:57:52.547504Z","iopub.status.idle":"2024-03-08T10:57:52.554048Z","shell.execute_reply.started":"2024-03-08T10:57:52.547477Z","shell.execute_reply":"2024-03-08T10:57:52.552959Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DataCollatorForLanguageModeling(tokenizer=GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"},"metadata":{}}]},{"cell_type":"code","source":"# Fine-tune the model\ntraining_args = TrainingArguments(\n    output_dir=\"./fine-tuned_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:58:06.671813Z","iopub.execute_input":"2024-03-08T10:58:06.672640Z","iopub.status.idle":"2024-03-08T10:58:07.983596Z","shell.execute_reply.started":"2024-03-08T10:58:06.672607Z","shell.execute_reply":"2024-03-08T10:58:07.982749Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-08T10:58:17.331179Z","iopub.execute_input":"2024-03-08T10:58:17.331914Z","iopub.status.idle":"2024-03-08T10:59:20.128031Z","shell.execute_reply.started":"2024-03-08T10:58:17.331883Z","shell.execute_reply":"2024-03-08T10:59:20.127020Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240308_105836-22owpe2g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/simranjeet97/huggingface/runs/22owpe2g' target=\"_blank\">spring-plant-6</a></strong> to <a href='https://wandb.ai/simranjeet97/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/simranjeet97/huggingface' target=\"_blank\">https://wandb.ai/simranjeet97/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/simranjeet97/huggingface/runs/22owpe2g' target=\"_blank\">https://wandb.ai/simranjeet97/huggingface/runs/22owpe2g</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 00:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30, training_loss=3.4812047322591146, metrics={'train_runtime': 62.4381, 'train_samples_per_second': 3.556, 'train_steps_per_second': 0.48, 'total_flos': 14501707776000.0, 'train_loss': 3.4812047322591146, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model\nmodel.save_pretrained(\"./fine-tuned_model_gpt2_wiki\")\n\n# Save the tokenizer\ntokenizer.save_pretrained(\"./fine-tuned_model_gpt2_wiki_token\")","metadata":{"execution":{"iopub.status.busy":"2024-03-08T11:02:01.612466Z","iopub.execute_input":"2024-03-08T11:02:01.612850Z","iopub.status.idle":"2024-03-08T11:02:02.660276Z","shell.execute_reply.started":"2024-03-08T11:02:01.612822Z","shell.execute_reply":"2024-03-08T11:02:02.659236Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned_model_gpt2_wiki_token/tokenizer_config.json',\n './fine-tuned_model_gpt2_wiki_token/special_tokens_map.json',\n './fine-tuned_model_gpt2_wiki_token/vocab.json',\n './fine-tuned_model_gpt2_wiki_token/merges.txt',\n './fine-tuned_model_gpt2_wiki_token/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load the fine-tuned model\nfine_tuned_model = GPT2LMHeadModel.from_pretrained(\"./fine-tuned_model_gpt2_wiki\")\nfine_tuned_tokenizer = GPT2Tokenizer.from_pretrained(\"./fine-tuned_model_gpt2_wiki_token\")\n\n# Text generation example\ngenerator = pipeline('text-generation', model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)\ngenerated_text = generator(\"What is Python?\", max_length=100, num_return_sequences=1)[0]['generated_text']\n\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-08T11:02:29.479724Z","iopub.execute_input":"2024-03-08T11:02:29.480594Z","iopub.status.idle":"2024-03-08T11:02:34.937666Z","shell.execute_reply.started":"2024-03-08T11:02:29.480553Z","shell.execute_reply":"2024-03-08T11:02:34.936671Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is Python?\nPython allows a wide variety of applications to run in parallel, depending on the environment. Many of the most commonly used programming languages:\n\nPyartes\nJava (and many other languages)\nC++\nC# (as well as Java, Python and Perl itself)\nPython is a Java programming language, developed by the University of Chicago's Computer Science Center. It includes a Java runtime, and supports both standard and custom runtime systems.\nAn application programming language\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}